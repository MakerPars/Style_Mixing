{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Style_Mixing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1vQYjCRRsdg",
        "colab_type": "text"
      },
      "source": [
        "**STYLE-MIXING NOTEBOOK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFlEtnHjRzon",
        "colab_type": "text"
      },
      "source": [
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMZ2kJk7R8yo",
        "colab_type": "text"
      },
      "source": [
        "**KURULUM-AYAR VS.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kqGGe1c9NGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==1.15\n",
        "%rm -rf /content/sample_data\n",
        "!git clone https://github.com/NVlabs/stylegan2.git\n",
        "%cd stylegan2\n",
        "%mkdir resim\n",
        "%mkdir aligned_resim\n",
        "%rm -rf /content/stylegan2/docs\n",
        "%rm /content/stylegan2/Dockerfile\n",
        "%rm /content/stylegan2/LICENSE.txt\n",
        "%rm /content/stylegan2/README.md"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4YLWH5NJOdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%mkdir networks\n",
        "%cd networks\n",
        "!wget http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXxZDFVnSC5J",
        "colab_type": "text"
      },
      "source": [
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPaV7fCBSpZO",
        "colab_type": "text"
      },
      "source": [
        "**Resim indir-düzenle-göster-align**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eioug0yRSwv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -O /content/stylegan2/resim/1.jpg 'https://external-preview.redd.it/lVUjjLxfqF7fIrqMslHnM8EVD6LQiO1yVnixSlco2W4.jpg?auto=webp&s=5d6c51f1be617680ebb5b64e4765c5d96269cec3'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avEKw_BVL0c-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "im1 = Image.open(r'/content/stylegan2/resim/1.jpg')\n",
        "im1.save(r'/content/stylegan2/resim/1.png')\n",
        "%rm /content/stylegan2/resim/1.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UV26QwyMRii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import PIL.Image\n",
        "img1 = PIL.Image.open('/content/stylegan2/resim/1.png')\n",
        "wpercent = (256/float(img1.size[0]))\n",
        "hsize = int((float(img1.size[1])*float(wpercent)))\n",
        "img1 = img1.resize((256,hsize), PIL.Image.LANCZOS)\n",
        "display(img1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmZfKM7D99Xk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#alıgnment kodu\n",
        "\n",
        "import os, sys, bz2,  dlib, scipy.ndimage, PIL.Image\n",
        "from keras.utils import get_file\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "RAW_IMAGES_DIR = \"/content/stylegan2/resim/\"\n",
        "ALIGNED_IMAGES_DIR = \"/content/stylegan2/aligned_resim/\"\n",
        "\n",
        "LANDMARKS_MODEL_URL = 'http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2'\n",
        "\n",
        "\n",
        "class LandmarksDetector:\n",
        "    def __init__(self, predictor_model_path):\n",
        "        \"\"\"\n",
        "        :param predictor_model_path: path to shape_predictor_68_face_landmarks.dat file\n",
        "        \"\"\"\n",
        "        self.detector = dlib.get_frontal_face_detector() # cnn_face_detection_model_v1 also can be used\n",
        "        self.shape_predictor = dlib.shape_predictor(predictor_model_path)\n",
        "\n",
        "    def get_landmarks(self, image):\n",
        "        img = dlib.load_rgb_image(image)\n",
        "        dets = self.detector(img, 1)\n",
        "\n",
        "        for detection in dets:\n",
        "            face_landmarks = [(item.x, item.y) for item in self.shape_predictor(img, detection).parts()]\n",
        "            yield face_landmarks\n",
        "\n",
        "\n",
        "def image_align(src_file, dst_file, face_landmarks, output_size=1024, transform_size=4096, enable_padding=True):\n",
        "        # Align function from FFHQ dataset pre-processing step\n",
        "        # https://github.com/NVlabs/ffhq-dataset/blob/master/download_ffhq.py\n",
        "\n",
        "        lm = np.array(face_landmarks)\n",
        "        lm_chin          = lm[0  : 17]  # left-right\n",
        "        lm_eyebrow_left  = lm[17 : 22]  # left-right\n",
        "        lm_eyebrow_right = lm[22 : 27]  # left-right\n",
        "        lm_nose          = lm[27 : 31]  # top-down\n",
        "        lm_nostrils      = lm[31 : 36]  # top-down\n",
        "        lm_eye_left      = lm[36 : 42]  # left-clockwise\n",
        "        lm_eye_right     = lm[42 : 48]  # left-clockwise\n",
        "        lm_mouth_outer   = lm[48 : 60]  # left-clockwise\n",
        "        lm_mouth_inner   = lm[60 : 68]  # left-clockwise\n",
        "\n",
        "        # Calculate auxiliary vectors.\n",
        "        eye_left     = np.mean(lm_eye_left, axis=0)\n",
        "        eye_right    = np.mean(lm_eye_right, axis=0)\n",
        "        eye_avg      = (eye_left + eye_right) * 0.5\n",
        "        eye_to_eye   = eye_right - eye_left\n",
        "        mouth_left   = lm_mouth_outer[0]\n",
        "        mouth_right  = lm_mouth_outer[6]\n",
        "        mouth_avg    = (mouth_left + mouth_right) * 0.5\n",
        "        eye_to_mouth = mouth_avg - eye_avg\n",
        "\n",
        "        # Choose oriented crop rectangle.\n",
        "        x = eye_to_eye - np.flipud(eye_to_mouth) * [-1, 1]\n",
        "        x /= np.hypot(*x)\n",
        "        x *= max(np.hypot(*eye_to_eye) * 2.0, np.hypot(*eye_to_mouth) * 1.8)\n",
        "        y = np.flipud(x) * [-1, 1]\n",
        "        c = eye_avg + eye_to_mouth * 0.1\n",
        "        quad = np.stack([c - x - y, c - x + y, c + x + y, c + x - y])\n",
        "        qsize = np.hypot(*x) * 2\n",
        "\n",
        "        # Load in-the-wild image.\n",
        "        if not os.path.isfile(src_file):\n",
        "            print('\\nCannot find source image. Please run \"--wilds\" before \"--align\".')\n",
        "            return\n",
        "        img = PIL.Image.open(src_file)\n",
        "\n",
        "        # Shrink.\n",
        "        shrink = int(np.floor(qsize / output_size * 0.5))\n",
        "        if shrink > 1:\n",
        "            rsize = (int(np.rint(float(img.size[0]) / shrink)), int(np.rint(float(img.size[1]) / shrink)))\n",
        "            img = img.resize(rsize, PIL.Image.ANTIALIAS)\n",
        "            quad /= shrink\n",
        "            qsize /= shrink\n",
        "\n",
        "        # Crop.\n",
        "        border = max(int(np.rint(qsize * 0.1)), 3)\n",
        "        crop = (int(np.floor(min(quad[:,0]))), int(np.floor(min(quad[:,1]))), int(np.ceil(max(quad[:,0]))), int(np.ceil(max(quad[:,1]))))\n",
        "        crop = (max(crop[0] - border, 0), max(crop[1] - border, 0), min(crop[2] + border, img.size[0]), min(crop[3] + border, img.size[1]))\n",
        "        if crop[2] - crop[0] < img.size[0] or crop[3] - crop[1] < img.size[1]:\n",
        "            img = img.crop(crop)\n",
        "            quad -= crop[0:2]\n",
        "\n",
        "        # Pad.\n",
        "        pad = (int(np.floor(min(quad[:,0]))), int(np.floor(min(quad[:,1]))), int(np.ceil(max(quad[:,0]))), int(np.ceil(max(quad[:,1]))))\n",
        "        pad = (max(-pad[0] + border, 0), max(-pad[1] + border, 0), max(pad[2] - img.size[0] + border, 0), max(pad[3] - img.size[1] + border, 0))\n",
        "        if enable_padding and max(pad) > border - 4:\n",
        "            pad = np.maximum(pad, int(np.rint(qsize * 0.3)))\n",
        "            img = np.pad(np.float32(img), ((pad[1], pad[3]), (pad[0], pad[2]), (0, 0)), 'reflect')\n",
        "            h, w, _ = img.shape\n",
        "            y, x, _ = np.ogrid[:h, :w, :1]\n",
        "            mask = np.maximum(1.0 - np.minimum(np.float32(x) / pad[0], np.float32(w-1-x) / pad[2]), 1.0 - np.minimum(np.float32(y) / pad[1], np.float32(h-1-y) / pad[3]))\n",
        "            blur = qsize * 0.02\n",
        "            img += (scipy.ndimage.gaussian_filter(img, [blur, blur, 0]) - img) * np.clip(mask * 3.0 + 1.0, 0.0, 1.0)\n",
        "            img += (np.median(img, axis=(0,1)) - img) * np.clip(mask, 0.0, 1.0)\n",
        "            img = PIL.Image.fromarray(np.uint8(np.clip(np.rint(img), 0, 255)), 'RGB')\n",
        "            quad += pad[:2]\n",
        "\n",
        "        # Transform.\n",
        "        img = img.transform((transform_size, transform_size), PIL.Image.QUAD, (quad + 0.5).flatten(), PIL.Image.BILINEAR)\n",
        "        if output_size < transform_size:\n",
        "            img = img.resize((output_size, output_size), PIL.Image.ANTIALIAS)\n",
        "\n",
        "        # Save aligned image.\n",
        "        img.save(dst_file, 'PNG')\n",
        "\n",
        "\n",
        "\n",
        "def unpack_bz2(src_path):\n",
        "    data = bz2.BZ2File(src_path).read()\n",
        "    dst_path = src_path[:-4]\n",
        "    with open(dst_path, 'wb') as fp:\n",
        "        fp.write(data)\n",
        "    return dst_path\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    landmarks_model_path = unpack_bz2(get_file('shape_predictor_68_face_landmarks.dat.bz2', LANDMARKS_MODEL_URL, cache_subdir='temp'))\n",
        "    landmarks_detector = LandmarksDetector(landmarks_model_path)\n",
        "    for img_name in os.listdir(RAW_IMAGES_DIR):\n",
        "        raw_img_path = os.path.join(RAW_IMAGES_DIR, img_name)\n",
        "        for i, face_landmarks in enumerate(landmarks_detector.get_landmarks(raw_img_path), start=1):\n",
        "            face_img_name = '%s_%02d.png' % (os.path.splitext(img_name)[0], i)\n",
        "            aligned_face_path = os.path.join(ALIGNED_IMAGES_DIR, face_img_name)\n",
        "            image_align(raw_img_path, aligned_face_path, face_landmarks)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gefSB3UkXGYL",
        "colab_type": "text"
      },
      "source": [
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcoMxRXKXJYd",
        "colab_type": "text"
      },
      "source": [
        "**DATASET OLUŞTUR**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S263GVQaNNKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python dataset_tool.py create_from_images Datasetler aligned_resim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwkg0nnqY4EY",
        "colab_type": "text"
      },
      "source": [
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnZXGv_pXw1v",
        "colab_type": "text"
      },
      "source": [
        "**PROJECT IMAGE-DLATENT OLUŞTUR**\n",
        "\n",
        "```\n",
        "# run_projector.py de project_image() fonksiyonuna\n",
        "```\n",
        "\n",
        "```\n",
        "np.save(png_prefix + '-dlatent.npy', proj.get_dlatents())\n",
        "np.save(png_prefix + '-noise.npy', proj.get_noises())\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4bxBKt8ATO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python run_projector.py project-real-images --network=networks/stylegan2-ffhq-config-f.pkl --dataset=Datasetler --data-dir=. --num-images=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwcPYnhHI5XU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import re\n",
        "import sys\n",
        "\n",
        "import pretrained_networks\n",
        "\n",
        "def style_mixing(dlatent, col_seeds, truncation_psi, col_styles, minibatch_size=4):\n",
        "    print('Loading networks from ...')\n",
        "    _G, _D, Gs = pretrained_networks.load_networks('networks/stylegan2-ffhq-config-f.pkl')\n",
        "    w_avg = Gs.get_var('dlatent_avg') # [component]\n",
        "    row_seeds = [80]\n",
        "    Gs_syn_kwargs = dnnlib.EasyDict()\n",
        "    Gs_syn_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_syn_kwargs.randomize_noise = False\n",
        "    Gs_syn_kwargs.minibatch_size = 1 #minibatch_size\n",
        "\n",
        "    print('Generating W vectors...')\n",
        "    all_seeds = list(set(col_seeds))\n",
        "    all_z = np.stack([np.random.RandomState(seed).randn(*Gs.input_shape[1:]) for seed in all_seeds]) # [minibatch, component]\n",
        "\n",
        "    all_w = Gs.components.mapping.run(all_z, None) # [minibatch, layer, component]\n",
        "    all_w = np.concatenate((all_w, dlatent), 0)\n",
        "    all_w = w_avg + (all_w - w_avg) * truncation_psi # [minibatch, layer, component]\n",
        "    all_seeds.extend(row_seeds) #= list(set(col_seeds + row_seeds))\n",
        "    w_dict = {seed: w for seed, w in zip(all_seeds, list(all_w))} # [layer, component]\n",
        "    \n",
        "    print('Generating images...')\n",
        "    all_images = Gs.components.synthesis.run(all_w, **Gs_syn_kwargs) # [minibatch, height, width, channel]\n",
        "    image_dict = {(seed, seed): image for seed, image in zip(all_seeds, list(all_images))}\n",
        "\n",
        "    print('Generating style-mixed images...')\n",
        "    for row_seed in row_seeds:\n",
        "        for col_seed in col_seeds:\n",
        "            w = w_dict[row_seed].copy()\n",
        "            # We set col_styles in this part\n",
        "            w[3:8] = w_dict[col_seed][3:8]\n",
        "            image = Gs.components.synthesis.run(w[np.newaxis], **Gs_syn_kwargs)[0]\n",
        "            image_dict[(row_seed, col_seed)] = image\n",
        "\n",
        "    print('Saving images...')\n",
        "    for (row_seed, col_seed), image in image_dict.items():\n",
        "        PIL.Image.fromarray(image, 'RGB').save(dnnlib.make_run_dir_path('mix/'+'%d-%d.png' % (row_seed, col_seed)))\n",
        "\n",
        "    print('Saving image grid...')\n",
        "    _N, _C, H, W = Gs.output_shape\n",
        "    canvas = PIL.Image.new('RGB', (W * (len(col_seeds) + 1), H * (len(row_seeds) + 1)), 'black')\n",
        "    for row_idx, row_seed in enumerate([None] + row_seeds):\n",
        "        for col_idx, col_seed in enumerate([None] + col_seeds):\n",
        "            if row_seed is None and col_seed is None:\n",
        "                continue\n",
        "            key = (row_seed, col_seed)\n",
        "            if row_seed is None:\n",
        "                key = (col_seed, col_seed)\n",
        "            if col_seed is None:\n",
        "                key = (row_seed, row_seed)\n",
        "            canvas.paste(PIL.Image.fromarray(image_dict[key], 'RGB'), (W * col_idx, H * row_idx))\n",
        "    canvas.save(dnnlib.make_run_dir_path('mix/grid.png'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0cScNCQZSDr",
        "colab_type": "text"
      },
      "source": [
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr-JaljgZUUK",
        "colab_type": "text"
      },
      "source": [
        "**STYLE-MIX**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6k_k_8kPp-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%mkdir mix\n",
        "dlat = np.load('/content/stylegan2/results/00000-project-real-images/image0000--dlatent.npy')\n",
        "style_mixing(dlat, [1], 0.5, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e2MVRt3ZfxT",
        "colab_type": "text"
      },
      "source": [
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoQhv8AIZY0z",
        "colab_type": "text"
      },
      "source": [
        "**TÜM  RESİMLERİ VE GRIDLERİ GÖSTER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJSvbJKQPviO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display(PIL.Image.open('/content/stylegan2/mix/1-1.png').resize((256,256)))\n",
        "display(PIL.Image.open('/content/stylegan2/mix/80-80.png').resize((256,256)))\n",
        "display(PIL.Image.open('/content/stylegan2/mix/80-1.png').resize((256,256)))\n",
        "print(\"------------------------------------------------------------------\")\n",
        "print(\"------------------------------------------------------------------\")\n",
        "print(\"------------------------------------------------------------------\")\n",
        "\n",
        "print(\"-------------------GRID----------------------\")\n",
        "display(PIL.Image.open('/content/stylegan2/mix/grid.png').resize((512,512)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW0esP_QZl0s",
        "colab_type": "text"
      },
      "source": [
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5nQnkCcZm1U",
        "colab_type": "text"
      },
      "source": [
        "**TEMİZLE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIe3N-7DQRzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%rm -rf /content/stylegan2/Datasetler\n",
        "%rm -rf /content/stylegan2/aligned_resim\n",
        "%rm -rf /content/stylegan2/networks\n",
        "%rm -rf /content/stylegan2/resim\n",
        "%rm -rf /content/stylegan2/results"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
